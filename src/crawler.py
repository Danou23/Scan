from bs4 import BeautifulSoup as bs
from error_handler import *
from scraper import *
from seleniumbase import SB
from force_fullmode import *

def searchByName(sb, website : str, name : str) -> list[tuple[str,str]]:
    """Searches for a manga by its name on the website.
    Args :
        website : website to search on
        name : name of the manga
        
    Returns :
        list of tuples (manga name, manga url)"""
    if not checkValidWebsite(website):
        raise InvalidWebsite(f"{website} not supported.")
    sb.driver.get(f"https://{website}/?s={'+'.join(name.split(' '))}") #replace every blank space by a + 
    soup = bs(sb.driver.page_source,'html.parser')
    children_divs = [a.findChildren()[0] for a in soup.find_all("div",{"class" : "bsx"})]
    results_list = [(a["title"],a["href"]) for a in children_divs]
    return results_list

def chooseFromResults(results_list : list[tuple[str,str]]) -> str:
    """Asks the user to choose a manga from the results list.
    Args :
        results_list : list of tuples (manga name, manga url), generated by searchByName
    Returns :
        url of the chosen manga
    """
    res = int(input(f"From your input, here are the available results.Select one : {','.join([i[0] for i in results_list])}\n"))
    return results_list[res - 1][1]

def getAvailableChapters(sb, url : str) -> list[str]:
    """Returns a list of available chapters from the manga's main page url.
    Args :
        url : link to the manga
    Returns :
        list of available chapters
    """
    sb.driver.get(url)
    soup = bs(sb.driver.page_source,'html.parser')
    chapterlist = soup.find_all("div",{"class" :"eph-num"})
    chapters_urls = [a.findChildren()[0]["href"] for a in chapterlist]
    return chapters_urls

def generateFolderName(chapter_url : str) -> str:
    """Generates a folder name from the chapter url
    Args :
        chapter_url : url of the chapter
    Returns :
        folder name
    """
    return f"{chapter_url.split('/')[-2]}/"

def downloadChapters(chapters : list[str],out_folder : str) -> None:
    """
    Downloads every chapter from the list of chapters's urls.
    Args :
        chapters : list of chapters's urls
        out_folder : folder to store the chapters
    """
    for chapter in chapters:
        folder_name = generateFolderName(chapter)
        path = f"{out_folder}{folder_name}"
        os.mkdir(path)
        chapter_imgs_urls = forceFullMode(sb,chapter)
        chapter_imgs_filenames = downloadImages(chapter_imgs_urls,path)
        mergeImagesToPDF(chapter_imgs_filenames,path)
        clearFolder(path)

if __name__ == "__main__":
    website = ALLOWED_WEBSITES[int(input("Choose a website : 1) anime-sama.me 2)sushiscan.fr\n")) - 1]
    with SB(uc=True,headless=True) as sb:
        choice = chooseFromResults(searchByName(sb,website,input()))
        chapters = getAvailableChapters(sb,choice)  
        downloadChapters(chapters,"./test/")

